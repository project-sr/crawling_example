{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 금융 해외증시\n",
    "\n",
    "https://finance.naver.com/world/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from splinter.driver.webdriver import BaseWebDriver, WebDriverElement\n",
    "import pandas as pd \n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "\n",
    "url = \"https://finance.naver.com/world/\"\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html,\"html.parser\",from_encoding='utf-8')\n",
    "\n",
    "hrefs = []\n",
    "urls = []\n",
    "\n",
    "#해외증시 url 다 가져오기\n",
    "\n",
    "for link in soup.findAll(\"a\"):\n",
    "    if 'href' in link.attrs:\n",
    "        hrefs.append(link.attrs['href'])\n",
    "\n",
    "for li in hrefs:\n",
    "    if '/world/sise.nhn?' in li:\n",
    "        urls.append(li)\n",
    "        \n",
    "url1 = urls[:-5][0::2]\n",
    "url2 = urls[-5:]\n",
    "url_final = url1 + url2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://finance.naver.com\"\n",
    "options = Options()\n",
    "options.add_argument('--start-maximized')\n",
    "\n",
    "browser = BaseWebDriver()\n",
    "driver = Chrome(\"C:/Users/glam/Desktop/chromedriver_win32/chromedriver.exe\",chrome_options=options)\n",
    "\n",
    "\n",
    "\n",
    "for urlss in url_final:\n",
    "    \n",
    "    name = []\n",
    "    final_data = []\n",
    "    days = []\n",
    "    html = url+urlss\n",
    "    driver.get(html)\n",
    "    \n",
    "    for i in range(1,10):\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        driver.find_element_by_xpath(\"\"\"//*[@id=\"dayLink\"\"\" + str(i) + \"\"\"\"]\"\"\").click()\n",
    "        result = driver.page_source\n",
    "        soup = BeautifulSoup(result,\"html.parser\",from_encoding='utf-8')\n",
    "        final_price = soup.findAll(\"td\",{\"class\" : \"tb_td2\"})\n",
    "        list_final_price = []\n",
    "        date = soup.findAll(\"td\",{\"class\" : \"tb_td\"})\n",
    "        dates = [re.sub('[^0-9]',\"\",str(day)) for day in date]\n",
    "\n",
    "        for i in final_price:\n",
    "            first = str(i).split(\"<span>\")[1]\n",
    "            second = first.split(\"</span>\")[0]\n",
    "            third = second.split(\".\")[0]\n",
    "            forth = re.sub(\",\",\"\",third)\n",
    "            final_data.append(int(forth))\n",
    "    \n",
    "        days = days + dates\n",
    "        \n",
    "    frame = pd.DataFrame({'date':days,\n",
    "                         'price':final_data})\n",
    "    print(frame)    \n",
    "    name.append(urlss.split(\"=\")[1])\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
